{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tanzania Tourism Prediction - Prognozy dotyczące turystyki w Tanzanii\n",
    "<h2>Autorzy:</h2><br>\n",
    "<ul>\n",
    "<li>Piotr Janiszek 247678</li>\n",
    "<li>Kacper Białek 247629</li>\n",
    "<li>Franciszek Pawlak 247756</li>\n",
    "<li>Michał Korblit 242427</li>\n",
    "</ul>"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_test_iteration = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "id": "7613fbacfe81bc40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Imports</h3>",
   "id": "259a10b6942f3e3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n"
   ],
   "id": "a8d8b4bcc8072682",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Data loadind</h3>\n",
   "id": "bbebe9a3844f4307"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv('data/Train.csv')\n",
    "df_regions = pd.read_csv('data/regions.csv')\n",
    "\n",
    "corrections = {\n",
    "    'SWIZERLAND': 'SWITZERLAND',\n",
    "    'MALT': 'MALTA',\n",
    "    'BURGARIA': 'BULGARIA',\n",
    "    'DRC': 'CONGO (DEMOCRATIC REPUBLIC OF THE)',\n",
    "    'KOREA': 'SOUTH KOREA',\n",
    "    'SWAZILAND': 'ESWATINI',\n",
    "    'UKRAIN': 'UKRAINE',\n",
    "    'TRINIDAD TOBACCO': 'TRINIDAD AND TOBAGO',\n",
    "    'COMORO': 'COMOROS',\n",
    "    'COSTARICA': 'COSTA RICA',\n",
    "    'PHILIPINES': 'PHILIPPINES',\n",
    "    'IVORY COAST': \"CÔTE D'IVOIRE\",\n",
    "    'DJIBOUT': 'DJIBOUTI',\n",
    "    'MORROCO': 'MOROCCO',\n",
    "    'UNITED STATES OF AMERICA': 'UNITED STATES',\n",
    "    'UAE': 'UNITED ARAB EMIRATES',\n",
    "    'SCOTLAND': 'UNITED KINGDOM',\n",
    "    'CAPE VERDE': 'CABO VERDE',\n",
    "}\n",
    "\n",
    "df_train['country'] = df_train['country'].replace(corrections)\n",
    "df_regions = df_regions[['name', 'sub-region']]\n",
    "df_regions = df_regions.rename(columns={'sub-region': 'region'})\n",
    "df_regions['name'] = df_regions['name'].str.upper()\n",
    "df_train = pd.merge(df_train, df_regions, how='left', left_on='country', right_on='name')\n",
    "df_train = df_train.drop(columns=['name'])\n",
    "\n",
    "print(df_train.columns)\n",
    "print(df_regions.columns)\n"
   ],
   "id": "3e60d14fd29bf9cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Data Cleaning</h3>",
   "id": "e81356a754097e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "count = df_train.isna().any(axis=1).sum()\n",
    "df_train.loc[df_train['most_impressing'].isna(), 'most_impressing'] = 'No comments'\n",
    "count2 = df_train.isna().any(axis=1).sum()\n",
    "\n",
    "mask_valid = (df_train['total_male'].notna()) & \\\n",
    "             (df_train['total_female'].notna()) & \\\n",
    "             ((df_train['total_male'] + df_train['total_female']) != 0)\n",
    "df_train.loc[mask_valid, 'total_cost_per_person'] = df_train.loc[mask_valid, 'total_cost'] / (\n",
    "            df_train.loc[mask_valid, 'total_male'] + df_train.loc[mask_valid, 'total_female'])\n",
    "mean = df_train.loc[mask_valid, 'total_cost_per_person'].mean()\n",
    "print(\"Średnia bez wierszy z zerową sumą:\", mean)\n",
    "\n",
    "\n",
    "# idzie przez kolumny z nan\n",
    "for index, row in df_train[df_train.isna().any(axis=1)].iterrows():\n",
    "    if (pd.isna(row['total_male']) | pd.isna(row['total_female'])) & (not (pd.isna(row['total_male']) & pd.isna(row['total_female']))):\n",
    "        if pd.isna(row['total_male']):\n",
    "            difference = row['total_cost'] - (row['total_female'] * mean)\n",
    "            person_left = difference / mean\n",
    "            person_left = round(person_left, 0)\n",
    "\n",
    "            if person_left < 0:\n",
    "                person_left = 0\n",
    "            #print(f\"Inserting {person_left}\")\n",
    "            df_train.loc[index, 'total_male'] = person_left\n",
    "\n",
    "        else:\n",
    "            difference = row['total_cost'] - (row['total_male'] * mean)\n",
    "\n",
    "            person_left = difference / mean\n",
    "            person_left = round(person_left, 0)\n",
    "\n",
    "            if person_left < 0:\n",
    "                person_left = 0\n",
    "            #print(f\"Inserting {person_left}\")\n",
    "            df_train.loc[index, 'total_female'] = person_left\n",
    "\n",
    "for index, row in df_train[df_train.isna().any(axis=1)].iterrows():\n",
    "    # Completing the travel_with field with the value Alone, when the number of people shows that he/she travels alone\n",
    "    if pd.isna(row['travel_with']) & ((row['total_male'] + row['total_female']) == 1):\n",
    "        df_train.loc[index, 'travel_with'] = 'Alone'\n"
   ],
   "id": "da3f9d979344bc1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random forest imputation\n",
    "mask_valid = (df_train['total_male'].notna()) & \\\n",
    "             (df_train['total_female'].notna()) & \\\n",
    "             ((df_train['total_male'] + df_train['total_female']) != 0)\n",
    "df_train.loc[mask_valid, 'total_cost_per_person'] = df_train.loc[mask_valid, 'total_cost'] / (\n",
    "            df_train.loc[mask_valid, 'total_male'] + df_train.loc[mask_valid, 'total_female'])\n",
    "mean = df_train.loc[mask_valid, 'total_cost_per_person'].mean()\n",
    "\n",
    "features = ['region', 'age_group', 'total_female',\n",
    "       'total_male', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "# Określ dozwolone kategorie - Model 1\n",
    "allowed_categories = ['Friends/Relatives', 'Children']\n",
    "# Filtrowanie danych treningowych - uwzględniamy tylko dozwolone kategorie\n",
    "df_train_imp = df_train[df_train['travel_with'].isin(allowed_categories)].copy()\n",
    "X_train = pd.get_dummies(df_train_imp[features], columns=features_cat)\n",
    "y_train = df_train_imp['travel_with']\n",
    "# Trenowanie modelu\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Określ dozwolone kategorie - Model 2\n",
    "allowed_categories2 = ['Children', 'Friends/Relatives', 'Spouse', 'Spouse and Children']\n",
    "# Filtrowanie danych treningowych - uwzględniamy tylko dozwolone kategorie\n",
    "df_train_imp2 = df_train[df_train['travel_with'].isin(allowed_categories2)].copy()\n",
    "X_train2 = pd.get_dummies(df_train_imp2[features], columns=features_cat)\n",
    "y_train2 = df_train_imp2['travel_with']\n",
    "# Trenowanie modelu\n",
    "rf2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf2.fit(X_train2, y_train2)\n",
    "\n",
    "# Określ dozwolone kategorie - Model 3\n",
    "features3 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat3 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "def designate_sex(row):\n",
    "    if (row['travel_with'] == 'Alone') and ((row['total_male'] + row['total_female']) == 1):\n",
    "        # Jeśli total_male == 1, przyjmujemy, że to mężczyzna, w przeciwnym razie kobieta\n",
    "        return 'Male' if row['total_male'] == 1 else 'Female'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_train['gender'] = df_train.apply(designate_sex, axis=1)\n",
    "df_model = df_train[df_train['gender'].notna()].copy()\n",
    "\n",
    "# Wybór cech (features) i zmienna docelowa (target)\n",
    "X_train3 = df_model[features3]\n",
    "y_train3 = df_model['gender']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), features_cat3)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train3, y_train3)\n",
    "\n",
    "# Predykcja płci dzieci - Model 4\n",
    "features4 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat4 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "df_train['male_children'] = df_train['total_male'].apply(lambda x: max(x - 1, 0))\n",
    "df_train['female_children'] = df_train['total_female'].apply(lambda x: max(x - 1, 0))\n",
    "\n",
    "df_filtered = df_train[(df_train['total_male'] > 0) & (df_train['total_female'] > 0)].copy()\n",
    "df_children_model = df_filtered[df_filtered['travel_with'] == 'Spouse and Children'].copy()\n",
    "\n",
    "# Przygotowanie macierzy cech\n",
    "X_train_child = pd.get_dummies(df_children_model[features4], columns=features_cat4)\n",
    "\n",
    "# Przygotowanie macierzy target – dwie kolumny: liczba dzieci mężczyzn i dzieci kobiet\n",
    "y_train_child = df_children_model[['male_children', 'female_children']]\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "multioutput_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "# Trenowanie modelu\n",
    "multioutput_rf.fit(X_train_child, y_train_child)\n",
    "\n",
    "# Predykcja podziału dzieci oraz dorosłego - Model 5\n",
    "features5 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat5 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "df_filtered = df_train[(df_train['total_male'] + df_train['total_female'] > 1)].copy()\n",
    "df_children_only_model = df_filtered[df_filtered['travel_with'] == 'Children'].copy()\n",
    "\n",
    "X_train_child_only = pd.get_dummies(df_children_only_model[features5], columns=features_cat5)\n",
    "y_train_child_only = df_children_only_model[['total_male', 'total_female']]\n",
    "\n",
    "multioutput_rf_children_only = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "multioutput_rf_children_only.fit(X_train_child_only, y_train_child_only)\n",
    "\n",
    "# Predykcja podziału przyjaciół - Model 6\n",
    "features6 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat6 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "df_filtered = df_train[(df_train['total_male'] + df_train['total_female'] > 1)].copy()\n",
    "df_friend_model = df_filtered[df_filtered['travel_with'] == 'Friends/Relatives'].copy()\n",
    "\n",
    "X_train_friends = pd.get_dummies(df_friend_model[features6], columns=features_cat6)\n",
    "y_train_friends = df_friend_model[['total_male', 'total_female']]\n",
    "\n",
    "multioutput_rf_friends = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "multioutput_rf_friends.fit(X_train_friends, y_train_friends)\n",
    "\n",
    "# predykcja kategori  - Model 7\n",
    "features7 = ['region', 'age_group', 'total_female',\n",
    "       'total_male', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat7 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "\n",
    "allowed_categories7 = ['Friends/Relatives', 'Children', 'Spouse and Children']\n",
    "# Filtrowanie danych treningowych - uwzględniamy tylko dozwolone kategorie\n",
    "df_train_imp7 = df_train[df_train['travel_with'].isin(allowed_categories7)].copy()\n",
    "X_train7 = pd.get_dummies(df_train_imp7[features7], columns=features_cat7)\n",
    "y_train7 = df_train_imp7['travel_with']\n",
    "# Trenowanie modelu\n",
    "rf7 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf7.fit(X_train7, y_train7)\n",
    "\n",
    "# Predykcja podziału dla wycieczki widmo - Model 8\n",
    "features8 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source',\n",
    "       'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "       'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "       'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "       'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing',\n",
    "       'total_cost']\n",
    "\n",
    "features_cat8 = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "df_filtered_phantom = df_train[(df_train['total_male'] + df_train['total_female'] > 1)].copy()\n",
    "df_phantom_model = df_filtered_phantom[(df_filtered_phantom['travel_with'] == 'Friends/Relatives') | (df_filtered_phantom['travel_with'] == 'Spouse and Children') | (df_filtered_phantom['travel_with'] == 'Children')].copy()\n",
    "\n",
    "X_train_phantom = pd.get_dummies(df_phantom_model[features8], columns=features_cat8)\n",
    "y_train_phantom = df_phantom_model[['total_male', 'total_female']]\n",
    "\n",
    "multioutput_rf_phantom = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "multioutput_rf_phantom.fit(X_train_phantom, y_train_phantom)\n",
    "\n",
    "# Predykcja travel with dla rekordu widmo\n",
    "allowed_categories8 = ['Children', 'Friends/Relatives', 'Spouse and Children']\n",
    "# Filtrowanie danych treningowych - uwzględniamy tylko dozwolone kategorie\n",
    "df_train_imp8 = df_train[df_train['travel_with'].isin(allowed_categories8)].copy()\n",
    "X_train8 = pd.get_dummies(df_train_imp8[features8], columns=features_cat8)\n",
    "y_train8 = df_train_imp8['travel_with']\n",
    "# Trenowanie modelu\n",
    "rf8 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf8.fit(X_train8, y_train8)\n",
    "\n",
    "# Imputation\n",
    "for index, row in df_train[df_train.isna().any(axis=1)].iterrows():\n",
    "    # Completing the travel_with field with the estimated value when only one gender participated in the trip and the number of people exceeds one\n",
    "    if (pd.isna(row['travel_with']) & ((row['total_male'] + row['total_female']) > 1) &\n",
    "            ((row['total_male'] == 0 | pd.isna(row['total_male'])) | (row['total_female'] == 0 | pd.isna(row['total_female'])))):\n",
    "\n",
    "        dummy_df = pd.get_dummies(row[features], columns=features_cat)\n",
    "        dummy_df.columns = dummy_df.columns.astype(str)\n",
    "        dummy_df = dummy_df.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "        predicted_value = rf.predict(dummy_df)\n",
    "\n",
    "        df_train.loc[index, 'travel_with'] = predicted_value[0]\n",
    "\n",
    "    elif (row['total_male'] + row['total_female'] > 1) & (pd.isna(row['travel_with'])):\n",
    "\n",
    "        dummy_df = pd.get_dummies(row[features], columns=features_cat)\n",
    "        dummy_df.columns = dummy_df.columns.astype(str)\n",
    "        dummy_df = dummy_df.reindex(columns=X_train2.columns, fill_value=0)\n",
    "\n",
    "        predicted_value = rf2.predict(dummy_df)\n",
    "\n",
    "        print(predicted_value[0])\n",
    "        df_train.loc[index, 'travel_with'] = predicted_value[0]\n",
    "\n",
    "    elif (not pd.isna(row['travel_with'])) & (row['total_male'] == 0 | pd.isna(row['total_male'])) & (row['total_female'] == 0 | pd.isna(row['total_female'])):\n",
    "        print(\"Brakuje liczby osob\")\n",
    "        persons = round(row['total_cost'] / mean, 0)\n",
    "\n",
    "        if row['travel_with'] == 'Alone':\n",
    "            print('predykcja płci')\n",
    "\n",
    "            input_df = row[features3].to_frame().T\n",
    "\n",
    "            predicted_value = model_pipeline.predict(input_df)\n",
    "\n",
    "            if predicted_value[0] == 'Male':\n",
    "                df_train.loc[index, 'total_male'] = 1\n",
    "                df_train.loc[index, 'total_female'] = 0\n",
    "            else:\n",
    "                df_train.loc[index, 'total_male'] = 0\n",
    "                df_train.loc[index, 'total_female'] = 1\n",
    "        elif row['travel_with'] == 'Spouse':\n",
    "            df_train.loc[index, 'total_male'] = 1\n",
    "            df_train.loc[index, 'total_female'] = 1\n",
    "        elif row['travel_with'] == 'Spouse and Children':\n",
    "            df_train.loc[index, 'total_male'] = 1\n",
    "            df_train.loc[index, 'total_female'] = 1\n",
    "            if persons < 3:\n",
    "                persons = 3\n",
    "            print(f\"Predykcja płci dziecka, przy {persons} wszystkich osobach\")\n",
    "            persons = persons - 2\n",
    "\n",
    "            # Przygotowanie danych wejściowych dla modelu\n",
    "            dummy_df = pd.get_dummies(row[features3], columns=features_cat3)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train_child.columns, fill_value=0)\n",
    "\n",
    "            # Surowe predykcje liczby dzieci dla obu płci\n",
    "            pred = multioutput_rf.predict(dummy_df)\n",
    "            pred_male, pred_female = pred[0, 0], pred[0, 1]\n",
    "\n",
    "            # Skalowanie predykcji do znanej liczby dzieci (persons)\n",
    "            pred_sum = pred_male + pred_female\n",
    "            if pred_sum == 0:\n",
    "                ratio_male = 0.5  # zabezpieczenie, gdyby suma była zerowa\n",
    "            else:\n",
    "                ratio_male = pred_male / pred_sum\n",
    "            ratio_female = 1 - ratio_male\n",
    "\n",
    "            # Obliczenie ostatecznej liczby dzieci danej płci\n",
    "            male_children_final = round(persons * ratio_male)\n",
    "            female_children_final = persons - male_children_final\n",
    "\n",
    "            # Dodanie przewidywanej liczby dzieci do dorosłych\n",
    "            df_train.loc[index, 'total_male'] += male_children_final\n",
    "            df_train.loc[index, 'total_female'] += female_children_final\n",
    "\n",
    "            print(f\"Predykcja: {male_children_final} chłopców oraz {female_children_final} dziewczyn, przy {persons} żądanych osobach\")\n",
    "\n",
    "\n",
    "        elif row['travel_with'] == 'Children':\n",
    "            print(\"Predykcja płci dziecka\")\n",
    "\n",
    "            if persons < 2:\n",
    "                persons = 2\n",
    "\n",
    "            # Przygotowanie danych wejściowych dla modelu\n",
    "            dummy_df = pd.get_dummies(row[features5], columns=features_cat5)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train_child_only.columns, fill_value=0)\n",
    "\n",
    "            # Surowe predykcje liczby dzieci dla obu płci\n",
    "            pred = multioutput_rf_children_only.predict(dummy_df)\n",
    "            pred_male, pred_female = pred[0, 0], pred[0, 1]\n",
    "\n",
    "            # Skalowanie predykcji do znanej liczby osób (persons)\n",
    "            pred_sum = pred_male + pred_female\n",
    "            if pred_sum == 0:\n",
    "                ratio_male = 0.5  # zabezpieczenie, gdyby suma była zerowa\n",
    "            else:\n",
    "                ratio_male = pred_male / pred_sum\n",
    "            ratio_female = 1 - ratio_male\n",
    "\n",
    "            # Obliczenie ostatecznej liczby dzieci danej płci\n",
    "            male_final = round(persons * ratio_male)\n",
    "            female_final = persons - male_final\n",
    "\n",
    "            # Przypisanie przewidywanej liczby dzieci\n",
    "            df_train.loc[index, 'total_male'] = male_final\n",
    "            df_train.loc[index, 'total_female'] = female_final\n",
    "\n",
    "            print(f\"Predykcja: {male_final} chłopców oraz {female_final} dziewczyn, przy {persons} żądanych osobach\")\n",
    "\n",
    "        elif row['travel_with'] == 'Friends/Relatives':\n",
    "            print(\"Predykcja podziału\")\n",
    "\n",
    "            if persons < 2:\n",
    "                persons = 2\n",
    "\n",
    "            # Przygotowanie danych wejściowych dla modelu\n",
    "            dummy_df = pd.get_dummies(row[features6], columns=features_cat6)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train_friends.columns, fill_value=0)\n",
    "\n",
    "            # Surowe predykcje liczby osób dla obu płci\n",
    "            pred = multioutput_rf_friends.predict(dummy_df)\n",
    "            pred_male, pred_female = pred[0, 0], pred[0, 1]\n",
    "\n",
    "            # Skalowanie predykcji do znanej liczby osób (persons)\n",
    "            pred_sum = pred_male + pred_female\n",
    "            if pred_sum == 0:\n",
    "                ratio_male = 0.5  # zabezpieczenie, gdyby suma była zerowa\n",
    "            else:\n",
    "                ratio_male = pred_male / pred_sum\n",
    "            ratio_female = 1 - ratio_male\n",
    "\n",
    "            # Obliczenie ostatecznej liczby osób danej płci\n",
    "            male_final = round(persons * ratio_male)\n",
    "            female_final = persons - male_final\n",
    "\n",
    "            # Przypisanie przewidywanej liczby osób\n",
    "            df_train.loc[index, 'total_male'] = male_final\n",
    "            df_train.loc[index, 'total_female'] = female_final\n",
    "\n",
    "            print(f\"Predykcja: {male_final} mężczyzn oraz {female_final} kobiet, przy {persons} żądanych osobach\")\n",
    "        else:\n",
    "            print(f\"{row['travel_with']}\"\n",
    "              f\"\\n{row['total_male']}\"\n",
    "              f\"\\n{row['total_female']}\")\n",
    "\n",
    "    elif pd.isna(row['travel_with']) & ((row['total_male'] + row['total_female']) == 0):\n",
    "        persons = round(row['total_cost'] / mean, 0)\n",
    "\n",
    "        if persons <= 1:\n",
    "            print('predykcja płci')\n",
    "            df_train.loc[index, 'travel_with'] = 'Alone'\n",
    "\n",
    "            input_df = row[features3].to_frame().T\n",
    "\n",
    "            predicted_value = model_pipeline.predict(input_df)\n",
    "\n",
    "            if predicted_value[0] == 'Male':\n",
    "                df_train.loc[index, 'total_male'] = 1\n",
    "                df_train.loc[index, 'total_female'] = 0\n",
    "            else:\n",
    "                df_train.loc[index, 'total_male'] = 0\n",
    "                df_train.loc[index, 'total_female'] = 1\n",
    "\n",
    "        else:\n",
    "            print('predykcja płci i rozłożenia oraz kategorii travel_with')\n",
    "\n",
    "            # predykcja podziału osób\n",
    "            print(f\"Predykcja: {persons} osob\")\n",
    "\n",
    "            # Przygotowanie danych wejściowych dla modelu\n",
    "            dummy_df = pd.get_dummies(row[features8], columns=features_cat8)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train_phantom.columns, fill_value=0)\n",
    "\n",
    "            # Surowe predykcje liczby osób dla obu płci\n",
    "            pred = multioutput_rf_phantom.predict(dummy_df)\n",
    "            pred_male, pred_female = pred[0, 0], pred[0, 1]\n",
    "\n",
    "            # Skalowanie predykcji do znanej liczby osób (persons)\n",
    "            pred_sum = pred_male + pred_female\n",
    "            if pred_sum == 0:\n",
    "                ratio_male = 0.5  # zabezpieczenie, gdyby suma była zerowa\n",
    "            else:\n",
    "                ratio_male = pred_male / pred_sum\n",
    "            ratio_female = 1 - ratio_male\n",
    "\n",
    "            # Obliczenie ostatecznej liczby osób danej płci\n",
    "            male_final = round(persons * ratio_male)\n",
    "            female_final = persons - male_final\n",
    "\n",
    "            # Przypisanie przewidywanej liczby osób\n",
    "            df_train.loc[index, 'total_male'] = male_final\n",
    "            df_train.loc[index, 'total_female'] = female_final\n",
    "\n",
    "            row['total_male'] = male_final\n",
    "            row['total_female'] = female_final\n",
    "\n",
    "            print(f\"Predykcja: {male_final} mężczyzn oraz {female_final} kobiet, przy {persons} żądanych osobach\")\n",
    "\n",
    "            # predykcja kategorii\n",
    "            dummy_df = pd.get_dummies(row[features8], columns=features_cat8)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train8.columns, fill_value=0)\n",
    "\n",
    "            predicted_value = rf8.predict(dummy_df)\n",
    "\n",
    "            df_train.loc[index, 'travel_with'] = predicted_value[0]\n",
    "\n",
    "\n",
    "    elif pd.isna(row['travel_with']):\n",
    "        print(f\"{row['travel_with']}\"\n",
    "              f\"\\n{row['total_male']}\"\n",
    "              f\"\\n{row['total_female']}\")\n",
    "\n",
    "\n",
    "mask_valid = (df_train['total_male'].notna()) & \\\n",
    "             (df_train['total_female'].notna()) & \\\n",
    "             ((df_train['total_male'] + df_train['total_female']) != 0)\n",
    "df_train.loc[mask_valid, 'total_cost_per_person'] = df_train.loc[mask_valid, 'total_cost'] / (\n",
    "            df_train.loc[mask_valid, 'total_male'] + df_train.loc[mask_valid, 'total_female'])\n",
    "\n",
    "count3 = df_train.isna().any(axis=1).sum()\n",
    "\n",
    "print(\"Początkowa liczba wierszy z brakującymi wartościami:\", count)\n",
    "print(\"Liczba wierszy z brakującymi wartościami po uzupełnieniu braków w kolumnie most_impressing:\", count2)\n",
    "print(\"Końcowa liczba wierszy z brakującymi wartościami:\", count3)\n",
    "\n",
    "for column in df_train.columns:\n",
    "    empty_count = df_train[column].isna().sum()\n",
    "\n",
    "    if empty_count > 0:\n",
    "        print(f\"Column '{column}' has {empty_count} empty fields (NaN).\")\n",
    "\n",
    "for index, row in df_train[df_train.isna().any(axis=1)].iterrows():\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "unique_countries_nan = df_train[df_train['region'].isna()]['country'].unique()\n",
    "print(\"Państwa bez regionu: \", unique_countries_nan)\n",
    "\n",
    "\n",
    "df_train.drop([\"most_impressing\", \"gender\"], axis=1, inplace=True)\n",
    "df_train[\"total_people\"] = df_train[\"total_male\"] + df_train[\"total_female\"]\n"
   ],
   "id": "2c3c86783ea1b685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ustawienia walidacji krzyżowej",
   "id": "723de26a2ea5ea91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n"
   ],
   "id": "7e604bce95144678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tablice do przechowywania meta-features",
   "id": "8a68e53a5f2ef4e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "oof_preds_xgb = np.zeros(len(df_train))\n",
    "oof_preds_cat = np.zeros(len(df_train))\n",
    "oof_preds_lgb = np.zeros(len(df_train))\n",
    "meta_features = np.zeros((len(df_train), 3))\n"
   ],
   "id": "8546bc77dc3de5f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Przygotowanie danych",
   "id": "30a44c9d665c5036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(df_train.columns)\n",
    "# Konwersja kolumn `object` na `category`\n",
    "for col in df_train.select_dtypes(include=['object']).columns:\n",
    "    df_train[col] = df_train[col].astype('category')\n",
    "    new_col = \"cat_\" + col\n",
    "    df_train.rename(columns={col: new_col}, inplace=True)\n",
    "\n",
    "print(df_train.columns)\n",
    "# Przygotowanie danych wejściowych\n",
    "X = df_train.drop(columns=[\"total_cost\", \"cat_ID\", 'total_cost_per_person', 'male_children', 'female_children', 'total_people', \"cat_country\"])  # Dane wejściowe\n",
    "y = df_train[\"total_cost\"]\n",
    "print(X.columns)\n",
    "cat_features = [col for col in X.columns if col.startswith('cat_')]\n",
    "\n",
    "# Podział na zbiory treningowy i walidacyjny\n",
    "if is_test_iteration:\n",
    "    X, X_valid_end, y, y_valid_end = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "print(f\"Liczba wierszy w zbiorze danych treningowych: {len(X)}\")\n",
    "print(f\"Liczba wierszy w zbiorze wartości: {len(y)}\")\n"
   ],
   "id": "1da02e7ad811ae1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dostrajanie XGBoost",
   "id": "d663ceaeba67a8c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    # Zakresy hiperparametrów\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': seed,\n",
    "        'verbose': 0,\n",
    "        'enable_categorical': True\n",
    "    }\n",
    "\n",
    "    # Inicjalizacja modelu z parametrami\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    # KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Obliczenie metryki\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=kf,\n",
    "        scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "\n",
    "    mae = -scores.mean()\n",
    "\n",
    "    return mae\n",
    "\n",
    "\n",
    "# Tworzenie i optymalizacja dla XGBoost\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=150, show_progress_bar=True)\n",
    "\n",
    "print(\"Najlepsza wartość MAE:\", study.best_value)\n",
    "print(\"Najlepsze parametry:\", study.best_params)\n"
   ],
   "id": "8b79938095dda5bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dostrajanie CatBoost",
   "id": "8aeafa9d12083824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Strojenie modelu CatBoost\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_state': seed,\n",
    "        'verbose': False,\n",
    "        'cat_features': cat_features,\n",
    "        'leaf_estimation_iterations': 1,\n",
    "        'boosting_type': 'Ordered',\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    # KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores = cross_val_score(\n",
    "        model, X, y, cv=kf, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    mae = -scores.mean()\n",
    "    return mae\n",
    "\n",
    "\n",
    "# Tworzenie i optymalizacja dla CatBoost\n",
    "study_catboost = optuna.create_study(direction='minimize')\n",
    "study_catboost.optimize(objective_catboost, n_trials=5, show_progress_bar=True)\n",
    "\n",
    "print(\"Najlepsza wartość MAE dla CatBoost:\", study_catboost.best_value)\n",
    "print(\"Najlepsze parametry dla CatBoost:\", study_catboost.best_params)\n"
   ],
   "id": "f0a85a0150daf42b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dostrajanie LightGBM",
   "id": "23300a476d9c269f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Strojenie modelu LightGBM\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 30),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': seed\n",
    "    }\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    # KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores = cross_val_score(\n",
    "        model, X, y, cv=kf, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    mae = -scores.mean()\n",
    "    return mae\n",
    "\n",
    "\n",
    "# Tworzenie i optymalizacja dla LightGBM\n",
    "study_lightgbm = optuna.create_study(direction='minimize')\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=250, show_progress_bar=True)\n",
    "\n",
    "print(\"Najlepsza wartość MAE dla LightGBM:\", study_lightgbm.best_value)\n",
    "print(\"Najlepsze parametry dla LightGBM:\", study_lightgbm.best_params)\n"
   ],
   "id": "f25a7d72eaa15d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definicje modeli bazowych i ich parametrów",
   "id": "346daef877b03b2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "xgb_params_manual = {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': seed,\n",
    "              'enable_categorical': True, 'verbose': 1, 'use_label_encoder': False, 'eval_metric': 'mae'}\n",
    "cat_params_manual = {'n_estimators': 500, 'learning_rate': 0.05, 'random_state': seed, 'verbose': 1}\n",
    "lgb_params_manual = {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 6, 'random_state': seed, 'verbose': 1}\n",
    "\n",
    "xgb_params = {**study.best_params, 'enable_categorical': True, 'verbose': 1}\n",
    "cat_params = {**study_catboost.best_params, 'verbose': 1, 'leaf_estimation_iterations': 1, 'boosting_type': 'Ordered' }\n",
    "lgb_params = {**study_lightgbm.best_params, 'verbose': 1}\n"
   ],
   "id": "ee6f56a0360b89bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inicjalizacja modeli",
   "id": "75f8fcbecf3b1877"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "cat_model = CatBoostRegressor(**cat_params)\n",
    "lgb_model = LGBMRegressor(**lgb_params)\n",
    "\n",
    "models = [('xgb', xgb_model), ('cat', cat_model), ('lgb', lgb_model)]\n",
    "\n",
    "oof_preds = {\n",
    "    'xgb': np.zeros(len(X)),\n",
    "    'cat': np.zeros(len(X)),\n",
    "    'lgb': np.zeros(len(X))\n",
    "}\n"
   ],
   "id": "ecb152c018c54a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mae_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Trening CatBoost\n",
    "    cat_model.fit(X_train, y_train, cat_features=cat_features)\n",
    "    cat_preds = cat_model.predict(X_valid)\n",
    "    oof_preds['cat'][val_idx] = cat_preds\n",
    "    mae_scores.append(f\"CatBoost fold MAE: {mean_absolute_error(y_valid, cat_preds):.4f}\")\n",
    "\n",
    "    # Trening XGBoost\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_valid)\n",
    "    oof_preds['xgb'][val_idx] = xgb_preds\n",
    "    mae_scores.append(f\"XGBoost fold MAE: {mean_absolute_error(y_valid, xgb_preds):.4f}\")\n",
    "\n",
    "    # Trening LightGBM\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_preds = lgb_model.predict(X_valid)\n",
    "    oof_preds['lgb'][val_idx] = lgb_preds\n",
    "\n",
    "    mae_scores.append(f\"LightGBM fold MAE: {mean_absolute_error(y_valid, lgb_preds):.4f}\")\n",
    "\n",
    "meta_features = np.column_stack((\n",
    "    oof_preds['xgb'],  # kolumna z predykcji XGBoost\n",
    "    oof_preds['cat'],  # kolumna z predykcji CatBoost\n",
    "    oof_preds['lgb']   # kolumna z predykcji LightGBM\n",
    "))\n",
    "\n",
    "cat_model = CatBoostRegressor(**cat_params)\n",
    "cat_model.fit(X, y, cat_features=cat_features)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "lgb_model = LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "for score in mae_scores:\n",
    "    print(f\"Scores for learning meta model: {score}\")\n",
    "\n",
    "if is_test_iteration:\n",
    "    cat_preds = cat_model.predict(X_valid_end)\n",
    "    print(f\"CatBoost fold MAE full model: {mean_absolute_error(y_valid_end, cat_preds):.4f}\")\n",
    "\n",
    "    xgb_preds = xgb_model.predict(X_valid_end)\n",
    "    print(f\"XGBoost fold MAE full model: {mean_absolute_error(y_valid_end, xgb_preds):.4f}\")\n",
    "\n",
    "    lgb_preds = lgb_model.predict(X_valid_end)\n",
    "    print(f\"LightGBM fold MAE full model: {mean_absolute_error(y_valid_end, lgb_preds):.4f}\")\n",
    "\n",
    "def build_meta_model(input_dim, n_neurons1, n_neurons2, dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons1, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_neurons2, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # regresja\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mae')\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Zakresy hiperparametrów\n",
    "    n_neurons1 = trial.suggest_int(\"n_neurons1\", 32, 128)\n",
    "    n_neurons2 = trial.suggest_int(\"n_neurons2\", 16, 64)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    epochs = 100\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "\n",
    "    # Walidacji krzyżowa\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(meta_features):\n",
    "        X_train, X_val = meta_features[train_idx], meta_features[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = build_meta_model(meta_features.shape[1], n_neurons1, n_neurons2, dropout_rate, learning_rate)\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0,\n",
    "                  callbacks=[early_stop])\n",
    "\n",
    "        mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "        mae_scores.append(mae)\n",
    "    print(f\"MAE: {np.mean(mae_scores)}\")\n",
    "    # Zwracamy średnią wartość błędu\n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "\n",
    "# Uruchomienie optymalizacji\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Najlepsze hiperparametry: \", study.best_params)\n",
    "\n",
    "# Trenowanie finalnego modelu z najlepszymi hiperparametrami\n",
    "best_params = study.best_params\n",
    "meta_model = build_meta_model(meta_features.shape[1],\n",
    "                               best_params[\"n_neurons1\"],\n",
    "                               best_params[\"n_neurons2\"],\n",
    "                               best_params[\"dropout_rate\"],\n",
    "                               best_params[\"learning_rate\"])\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "meta_model.fit(meta_features, y, epochs=100, batch_size=best_params[\"batch_size\"], verbose=1, callbacks=[early_stop])\n"
   ],
   "id": "10b02a06efca814",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predykcje\n",
    "def space_formatter(x, pos):\n",
    "    return f\"{int(x):,}\".replace(',', ' ')\n",
    "\n",
    "predictions_combined = []\n",
    "\n",
    "if is_test_iteration:\n",
    "    # Predykcje bazowych modeli na danych nowych\n",
    "    preds_xgb = xgb_model.predict(X_valid_end)\n",
    "    preds_cat = cat_model.predict(X_valid_end)\n",
    "    preds_lgb = lgb_model.predict(X_valid_end)\n",
    "\n",
    "    # Łączenie predykcji w macierz\n",
    "    meta_features_new = np.column_stack((preds_xgb, preds_cat, preds_lgb))\n",
    "\n",
    "    # Predykcja finalna modelu meta\n",
    "    predictions = meta_model.predict(meta_features_new)\n",
    "\n",
    "    mae = mean_absolute_error(y_valid_end, predictions)\n",
    "    print(f\"Średni błąd bezwzględny:\", mae)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.hist(predictions, bins=20, alpha=0.7, color='blue', label='Predykcje')\n",
    "    plt.xlabel(\"Wartość błędu\")\n",
    "    plt.ylabel(\"Liczebność\")\n",
    "    plt.title(\"Histogram predykcji\")\n",
    "    plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(space_formatter))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "id": "7dc22f06bfbb58c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_test_iteration:\n",
    "    x = np.arange(len(y_valid_end))\n",
    "    y_valid_array = y_valid_end.to_numpy().flatten()\n",
    "    predictions_array = np.array(predictions).flatten()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Wykres punktowy dla wartości rzeczywistych (niebieski)\n",
    "    plt.scatter(x, y_valid_end, color='blue', label='Wartość rzeczywista')\n",
    "\n",
    "    # Wykres punktowy dla wartości estymowanych (czerwony)\n",
    "    plt.scatter(x, predictions, color='red', label='Wartość estymowana')\n",
    "\n",
    "    # Dla każdej pary linia łącząca punkty\n",
    "    for i in range(len(x)):\n",
    "        plt.plot([x[i], x[i]], [y_valid_array[i], predictions_array[i]], color='gray', linewidth=0.5)\n",
    "\n",
    "    plt.xlabel('Indeks')\n",
    "    plt.ylabel('Wartość')\n",
    "    plt.title(f'Porównanie wartości rzeczywistych i estymowanych')\n",
    "    plt.legend()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(space_formatter))\n",
    "\n",
    "    plt.show()\n"
   ],
   "id": "9998da652c2e985e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not is_test_iteration:\n",
    "    valid_preds = pd.read_csv('data/Test.csv')\n",
    "\n",
    "    corrections = {\n",
    "        'SWIZERLAND': 'SWITZERLAND',\n",
    "        'UNITED STATES OF AMERICA': 'UNITED STATES',\n",
    "        'COMORO': 'COMOROS',\n",
    "        'MALT': 'MALTA',\n",
    "        'UAE': 'UNITED ARAB EMIRATES',\n",
    "        'UKRAIN': 'UKRAINE',\n",
    "        'DRC': 'CONGO (DEMOCRATIC REPUBLIC OF THE)',\n",
    "        'SWAZILAND': 'ESWATINI',\n",
    "        'COSTARICA': 'COSTA RICA',\n",
    "        'SCOTLAND': 'UNITED KINGDOM',\n",
    "        'PHILIPINES': 'PHILIPPINES',\n",
    "        'BOSNIA': 'BOSNIA AND HERZEGOVINA',\n",
    "        'CAPE VERDE': 'CABO VERDE',\n",
    "        'MORROCO': 'MOROCCO',\n",
    "        'SOMALI': 'SOMALIA',\n",
    "        'KOREA': 'SOUTH KOREA',\n",
    "        'SAUD ARABIA': 'SAUDI ARABIA',\n",
    "    }\n",
    "\n",
    "    valid_preds['country'] = valid_preds['country'].replace(corrections)\n",
    "\n",
    "    valid_preds = pd.merge(valid_preds, df_regions, how='left', left_on='country', right_on='name')\n",
    "    valid_preds = valid_preds.drop(columns=['name'])\n",
    "    print(valid_preds.columns)\n",
    "\n",
    "    # Check before cleansing\n",
    "    for column in valid_preds.columns:\n",
    "        empty_count = valid_preds[column].isna().sum()\n",
    "\n",
    "        if empty_count > 0:\n",
    "            print(f\"Column '{column}' has {empty_count} empty fields (NaN).\")\n",
    "\n",
    "    valid_preds.loc[valid_preds['most_impressing'].isna(), 'most_impressing'] = 'No comments'\n",
    "\n",
    "    # Travel with imputation\n",
    "    features_tw = ['region', 'age_group', 'total_female',\n",
    "           'total_male', 'purpose', 'main_activity', 'info_source',\n",
    "           'tour_arrangement', 'package_transport_int', 'package_accomodation',\n",
    "           'package_food', 'package_transport_tz', 'package_sightseeing',\n",
    "           'package_guided_tour', 'package_insurance', 'night_mainland',\n",
    "           'night_zanzibar', 'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "    features_cat_tw = ['region', 'age_group', 'purpose', 'main_activity', 'info_source', 'tour_arrangement',\n",
    "                    'package_transport_int', 'package_accomodation', 'package_food', 'package_transport_tz',\n",
    "                    'package_sightseeing', 'package_guided_tour', 'package_insurance',\n",
    "                    'payment_mode', 'first_trip_tz', 'most_impressing']\n",
    "\n",
    "\n",
    "    # Filtrowanie danych treningowych - uwzględniamy tylko dozwolone kategorie\n",
    "    valid_preds_no_nan = valid_preds.dropna()\n",
    "\n",
    "    allowed_categories = ['Children', 'Friends/Relatives', 'Spouse', 'Spouse and Children']\n",
    "    valid_preds_imp = valid_preds_no_nan[valid_preds_no_nan['travel_with'].isin(allowed_categories)].copy()\n",
    "    X_train_tw = pd.get_dummies(valid_preds_imp[features_tw], columns=features_cat_tw)\n",
    "    y_train_tw = valid_preds_imp['travel_with']\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    rf_tw = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_tw.fit(X_train_tw, y_train_tw)\n",
    "\n",
    "    print(\"Cleansing test dataset\")\n",
    "    for index, row in valid_preds[valid_preds.isna().any(axis=1)].iterrows():\n",
    "        if pd.isna(row['travel_with']) & (row['total_male'] + row['total_female'] == 1) & (not pd.isna(row['total_male'])) & (not pd.isna(row['total_female'])):\n",
    "            valid_preds.loc[index, 'travel_with'] = 'Alone'\n",
    "        if pd.isna(row['travel_with']) & (row['total_male'] + row['total_female'] > 1) & (not pd.isna(row['total_male'])) & (not pd.isna(row['total_female'])):\n",
    "            dummy_df = pd.get_dummies(row[features_tw], columns=features_cat_tw)\n",
    "            dummy_df.columns = dummy_df.columns.astype(str)\n",
    "            dummy_df = dummy_df.reindex(columns=X_train_tw.columns, fill_value=0)\n",
    "\n",
    "            predicted_value = rf_tw.predict(dummy_df)\n",
    "\n",
    "            print(f\"\\nrow\"\n",
    "                  f\"\\n{row['travel_with']}\"\n",
    "                  f\"\\n{row['total_male']}\"\n",
    "                  f\"\\n{row['total_female']}\"\n",
    "                  f\"\\n{predicted_value[0]}\")\n",
    "\n",
    "            valid_preds.loc[index, 'travel_with'] = predicted_value[0]\n",
    "\n",
    "        if (row['travel_with'] == 'Alone') & ((pd.isna(row['total_male'])) | (pd.isna(row['total_female']))):\n",
    "            if pd.isna(row['total_female']):\n",
    "                valid_preds.loc[index, 'total_female'] = 0\n",
    "\n",
    "                print(f\"\\nrow\"\n",
    "                      f\"\\n{row['travel_with']}\"\n",
    "                      f\"\\n{row['total_male']}\"\n",
    "                      f\"\\n{row['total_female']}\"\n",
    "                      f\"\\n{0}\")\n",
    "            elif pd.isna(row['total_female']):\n",
    "                valid_preds.loc[index, 'total_male'] = 0\n",
    "\n",
    "                print(f\"\\nrow\"\n",
    "                      f\"\\n{row['travel_with']}\"\n",
    "                      f\"\\n{row['total_male']}\"\n",
    "                      f\"\\n{row['total_female']}\"\n",
    "                      f\"\\n{0}\")\n",
    "            elif pd.isna(row['total_male']) & pd.isna(row['total_female']):\n",
    "                # Gentleman\n",
    "                valid_preds.loc[index, 'total_male'] = 0\n",
    "                valid_preds.loc[index, 'total_female'] = 1\n",
    "\n",
    "        elif (pd.isna(row['total_female'])) & (row['total_male'] > 0):\n",
    "\n",
    "            if row['total_male'] > 1:\n",
    "                valid_preds.loc[index, 'total_female'] = 0\n",
    "            else:\n",
    "                valid_preds.loc[index, 'total_female'] = 1\n",
    "\n",
    "            print(f\"\\nrow\"\n",
    "                  f\"\\n{row['travel_with']}\"\n",
    "                  f\"\\n{row['total_male']}\"\n",
    "                  f\"\\n{row['total_female']}\"\n",
    "                  f\"\\n{0}\")\n",
    "\n",
    "        elif (pd.isna(row['total_male'])) & (row['total_female'] > 0):\n",
    "\n",
    "            if row['total_female'] > 1:\n",
    "                valid_preds.loc[index, 'total_male'] = 0\n",
    "            else:\n",
    "                valid_preds.loc[index, 'total_male'] = 1\n",
    "\n",
    "            print(f\"\\nrow\"\n",
    "                  f\"\\n{row['travel_with']}\"\n",
    "                  f\"\\n{row['total_male']}\"\n",
    "                  f\"\\n{row['total_female']}\"\n",
    "                  f\"\\n{0}\")\n",
    "\n",
    "        if (row['total_male'] + row['total_female'] == 0) & (not pd.isna(row['total_male'])) & (not pd.isna(row['total_female'])):\n",
    "\n",
    "            # Gentleman\n",
    "            valid_preds.loc[index, 'total_female'] = 1\n",
    "\n",
    "            if pd.isna(row['travel_with']):\n",
    "                dummy_df = pd.get_dummies(row[features_tw], columns=features_cat_tw)\n",
    "                dummy_df.columns = dummy_df.columns.astype(str)\n",
    "                dummy_df = dummy_df.reindex(columns=X_train_tw.columns, fill_value=0)\n",
    "\n",
    "                predicted_value = rf_tw.predict(dummy_df)\n",
    "\n",
    "                valid_preds.loc[index, 'travel_with'] = predicted_value[0]\n",
    "\n",
    "            print(f\"\\nrow widmo\"\n",
    "                  f\"\\n{row['travel_with']}\"\n",
    "                  f\"\\n{row['total_male']}\"\n",
    "                  f\"\\n{row['total_female']}\")\n",
    "\n",
    "    # Check after cleansing\n",
    "    for index, row in valid_preds[valid_preds.isna().any(axis=1)].iterrows():\n",
    "        if pd.isna(row['travel_with']) | pd.isna(row['total_male']) | pd.isna(row['total_female']):\n",
    "            print(f\"\\nrow\"\n",
    "                  f\"\\n{row['travel_with']}\"\n",
    "                  f\"\\n{row['total_male']}\"\n",
    "                  f\"\\n{row['total_female']}\")\n",
    "\n",
    "\n",
    "    for column in valid_preds.columns:\n",
    "        empty_count = valid_preds[column].isna().sum()\n",
    "\n",
    "        if empty_count > 0:\n",
    "            print(f\"Column '{column}' has {empty_count} empty fields (NaN).\")\n",
    "\n",
    "\n",
    "    unique_countries_nan = valid_preds[valid_preds['region'].isna()]['country'].unique()\n",
    "    print(\"\\nPaństwa bez regionu: \", unique_countries_nan)\n",
    "\n",
    "    for col in valid_preds.select_dtypes(include=['object']).columns:\n",
    "        if col != \"ID\":\n",
    "            valid_preds[col] = valid_preds[col].astype('category')\n",
    "            new_col = \"cat_\" + str(col)\n",
    "            valid_preds.rename(columns={col: new_col}, inplace=True)\n",
    "    print(valid_preds.columns)\n",
    "    valid_preds.drop(columns=['cat_most_impressing', 'cat_country'], inplace=True)\n",
    "    print(valid_preds.columns)\n"
   ],
   "id": "294053240eb1fde3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Challange predictions",
   "id": "3e8a21a5971fd217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not is_test_iteration:\n",
    "    id_valid = valid_preds['ID']\n",
    "    X_valid_preds = valid_preds.drop('ID', axis=1)\n",
    "\n",
    "    # Predykcje bazowych modeli\n",
    "    preds_xgb = xgb_model.predict(X_valid_preds)\n",
    "    preds_cat = cat_model.predict(X_valid_preds)\n",
    "    preds_lgb = lgb_model.predict(X_valid_preds)\n",
    "\n",
    "    # Łączenie predykcji dla meta modelu\n",
    "    meta_features_new = np.column_stack((preds_xgb, preds_cat, preds_lgb))\n",
    "\n",
    "    # Predykcja finalna\n",
    "    predictions = meta_model.predict(meta_features_new)\n",
    "\n",
    "    if predictions.ndim > 1 and predictions.shape[1] == 1:\n",
    "        predictions = predictions.ravel()\n",
    "\n",
    "    # Finalne dane predykcji\n",
    "    results = pd.DataFrame({\n",
    "        'ID': id_valid,\n",
    "        'total_cost': predictions\n",
    "    })\n",
    "\n",
    "\n",
    "    results.to_csv('data/submission.csv', index=False)\n"
   ],
   "id": "f6e5be0615358343",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
